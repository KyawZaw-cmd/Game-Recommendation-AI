# -*- coding: utf-8 -*-
"""Product Recommendation System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vt0VI-r8R9SiZaQiSOZ2GxLjnvPglU0-

# Content Based Recommendor

Importing Necessary Libraries
"""

#Basic Libraries
import numpy as np
import pandas as pd

#Visualization Libraries
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

#Text Handling Libraries
import re
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.metrics.pairwise import linear_kernel, cosine_similarity

"""Data Loading and Cleaning"""

df = pd.read_csv('productlist.csv')
df.head()

df.shape

df.isnull().sum()

print('Percentage Null Data In Each Column')
print('-'*30)
for col in df.columns:
    null_count = df[col].isnull().sum()
    total_count = df.shape[0]
    print("{} : {:.2f}".format(col,null_count/total_count * 100))

print('Total Null Data')
null_count = df.isnull().sum().sum()
total_count = np.product(df.shape)
print("{:.2f}".format(null_count/total_count * 100))

df = df.dropna()

df.isnull().sum()

df.shape

"""### Exploratory Data Analysis"""

counts = df['category'].value_counts()

counts_df = pd.DataFrame({'Category':counts.index,'Counts':counts.values})

px.bar(data_frame=counts_df,
 x='Category',
 y='Counts',
 color='Counts',
 color_continuous_scale='blues',
 text_auto=True,
 title=f'Count of Items in Each Category')

counts = df['sub_category'].value_counts()

counts_df_1 = pd.DataFrame({'Category':counts.index,'Counts':counts.values})[:10]

px.bar(data_frame=counts_df_1,
 x='Category',
 y='Counts',
 color='Counts',
 color_continuous_scale='blues',
 text_auto=True,
 title=f'Top 10 Bought Sub_Categories')

counts = df['type'].value_counts()

counts_df_type = pd.DataFrame({'Type':counts.index,'Counts':counts.values})[:10]

px.bar(data_frame=counts_df_type,
 x='Type',
 y='Counts',
 color='Counts',
 color_continuous_scale='blues',
 text_auto=True,
 title=f'Top 10 Types of Products based on Item Counts')

df.head()

tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(df['product'])
tfidf_matrix.shape

"""TF-IDF stands for term frequency-inverse document frequency.

# Recommending items based on similarity score
"""

cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)
cosine_sim

indices = pd.Series(df.index, index=df['product']).drop_duplicates()

def get_recommendations(title, cosine_sim=cosine_sim):

    idx = indices[title]
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:11]
    movie_indices = [i[0] for i in sim_scores]
    return df['product'].iloc[movie_indices]

get_recommendations('Resident Evil 3 PC + DLC')

get_recommendations('Command And Conquer : The Ultimate Edition PC')

get_recommendations('Monster Hunter: Iceborne')

get_recommendations('Call of Duty: Advanced Warfare')

get_recommendations('GTA V: Premium Online Edition')

"""# IMPROVING THE RESULTS OF RECOMMENDER

"""

df2 = df.copy()

df2.head()

df2.shape

rmv_spc = lambda a:a.strip()
get_list = lambda a:list(map(rmv_spc,re.split('& |, |\*|\n', a)))

get_list('A & B, C')

for col in ['category', 'sub_category', 'type']:
    df2[col] = df2[col].apply(get_list)

df2.head()

"""## To avoid duplicacy, we will be converting everything to lowercase and also removing spaces between words."""

def cleaner(x):
    if isinstance(x, list):
        return [str.lower(i.replace(" ", "")) for i in x]
    else:
        if isinstance(x, str):
            return str.lower(x.replace(" ", ""))
        else:
            return ''

for col in ['category', 'sub_category', 'type']:
    df2[col] = df2[col].apply(cleaner)

df2.head()

"""## We will now be joining the values of category, sub_category, type and brand"""

def couple(x):
    return ' '.join(x['category']) + ' ' + ' '.join(x['sub_category']) + ' ' + ' '.join( x['type'])
df2['soup'] = df2.apply(couple, axis=1)

df2['soup'].head()

df2.head()

df2.to_csv('data_cleaned_1.csv')

count = CountVectorizer(stop_words='english')
count_matrix = count.fit_transform(df2['soup'])

"""## We need to Count the String Vectors and then compute the Cosine Similarity Score."""

cosine_sim2 = cosine_similarity(count_matrix, count_matrix)
cosine_sim2

#Cosine Similarity Documentation

df2 = df2.reset_index()
indices = pd.Series(df2.index, index=df2['product'])

def get_recommendations_2(title, cosine_sim=cosine_sim):
    idx = indices[title]

    sim_scores = list(enumerate(cosine_sim[idx]))

    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    sim_scores = sim_scores[1:11]

    movie_indices = [i[0] for i in sim_scores]

    return df2['product'].iloc[movie_indices]

old_rec = get_recommendations('Call of Duty: Advanced Warfare').values
new_rec = get_recommendations_2('Call of Duty: Advanced Warfare', cosine_sim2).values

"""## Comparing Old and New Recommedations"""

pd.DataFrame({'Old Recommendor': old_rec,'New Recommendor':new_rec})

"""## Getting the Final Recommendations"""

get_recommendations_2('Call of Duty: Advanced Warfare')

get_recommendations_2('Resident Evil 3 PC + DLC')

get_recommendations_2('Forza Horizon 4 Xbox/PC')

get_recommendations_2('Yakuza: Like A Dragon PC')

"""# Thank You"""